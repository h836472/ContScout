#!/usr/bin/Rscript

byedie=function(x,log=TRUE,sure_q=TRUE)
{
cat(x)
if(log)
{
writeLines(x,con=logfile)
}
if(sure_q)
{
q(save="no",status=1)
}else
{
cat("\nFatal error found but quit cancelled by sure_q=FALSE...\n")
}
}

info=function(x,log=T){
cat(paste(x,"\n"))
if(log)
{
writeLines(x,con=logfile)
}
}

progname="ContScout"
info("This is ContScout, a contamination remover tool written in R.\n",log=F)
info("Loading R libraries.\n",log=F)
suppressPackageStartupMessages(library("optparse"))
suppressPackageStartupMessages(library("parallel"))
suppressPackageStartupMessages(library("bitops"))
suppressPackageStartupMessages(library("GenomicRanges"))
suppressPackageStartupMessages(library("rtracklayer"))
suppressPackageStartupMessages(library("huxtable"))
cargs=commandArgs(trailingOnly=T)
option_list = list(
  make_option(c("-a", "--aligner"), type="character", default="mmseqs", 
              help="Aligner software to use", metavar="userdir"),
  make_option(c("-u", "--userdir"), type="character", default=NULL, 
              help="Path to local database repository folder", metavar="userdir"),
  make_option(c("-c", "--cpu"), type="character", default="all", 
              help="Number of CPUs to use", metavar="cpu"),
  make_option(c("-d", "--dbname"), type="character", default=NULL,help="Name of the database to be used as a reference",metavar="dbname"),
  make_option(c("-i", "--inputdir"), type="character", default=NULL, 
              help="Input data directory containing fasta protein sequence and -optionally- GFF annotation file", metavar="inputdir"),
  make_option(c("-q", "--querytax"), type="character", default=NULL, 
              help="NCBI TaxonID for query", metavar="querytax"),
  make_option(c("-f", "--force"), action="store_true", default=FALSE, 
              help="Force the analysis despite inconsistencies between annotation file and fasta file."),
  make_option(c("-r", "--reuse_abc"), action="store_true", default=FALSE, 
              help="Reuse ABC file from previous run if possible."),
  make_option(c("-n", "--no_annot"), action="store_true",default=FALSE,  
              help="No annotation file is provided. Perform individual protein-based filtering."),
  make_option(c("-s", "--sens"), type="character", default="2", 
              help="Sensitivity value for MMSeqs search", metavar="sens"),
  make_option(c("-m", "--memlimit"), type="character", default=NULL, 
              help="Memory usage limit", metavar="memlimit"),
  make_option(c("-x", "--exclude_tax"), type="character", default="all",
              help="Set the taxonomical groups to remove.",metavar="exclude_tax"),
  make_option(c("-l", "--list_databases"), action="store_true", default=FALSE,
              help="List pre-formatted databases stored in the local database repository."),
  make_option(c("-p", "--pci"), type="character", default="20",
              help="Minimum percentage of sequence identity between query and hit.",metavar="pci"),
  make_option(c("-t", "--tmpdir"), type="character", default=NULL,
             help="Path to temp folder.",metavar="TEMP"));
opt_parser = OptionParser(option_list=option_list,prog=progname);
if(FALSE)
{
#manually set options, if needed for development
opt=list()
opt[["aligner"]]="diamond" # -a 
opt[["userdir"]]="/data/databases" #-u 
opt[["cpu"]]=16 #-c 
opt[["dbname"]]="demo" #-d 
opt[["inputdir"]]="/data/ContScout_Develop2023/Quersube" # -i
opt[["querytax"]]=58331 #-q 
opt[["force"]]=FALSE
opt[["reuse_abc"]]=FALSE #-r
opt[["no_annot"]]=FALSE
opt[["sens"]]=2 #-s 2
opt[["memlimit"]]="150G" #-m 
opt[["exclude_tax"]]="all" #-x 
opt[["list_databases"]]=FALSE
opt[["pci"]]=20 #-p 
opt[["tmpdir"]]="/cs_temp" #-t 
}else{
opt = parse_args(opt_parser);
}


startdir=getwd()
time_start=Sys.time()
logfilename=paste0("ContScout_",format(time_start,"%d%b_%Y_%H_%M"),".log")
logfile=file(logfilename,open="a") #copy log file to output folder once we are done!

if (is.null(opt[["inputdir"]]))
{
byedie("Please specify an input directory that contains the protein sequence and annotation file!\n")
}
setwd(opt[["inputdir"]])

#user dir check
if(is.null(opt[["userdir"]]))
{
byedie("Please provide the path to your user directory with the pre-formatted reference databases.\n")
}

#tmpdir check and set
if(is.null(opt[["tmpdir"]]))
{
opt[["tmpdir"]]=paste0(opt[["userdir"]],"/tmp")
}
if(!file.exists(opt[["tmpdir"]]))
{dir.create(opt[["tmpdir"]])}

#memlimit check
if (!is.null(opt[["memlimit"]])&&!grepl("^\\d+G$",opt[["memlimit"]]))
{
byedie(paste0('Please provide a memory limit in {num}G format. Example: 150G!\n'))
}

#aligner check
opt[["aligner"]]=tolower(opt[["aligner"]])
if(!opt[["aligner"]]%in%c("mmseqs","diamond"))
{
byedie("Please select MMSeqs (-a mmseqs) or Diamond (-a diamond) as your preferred aligner!\n")
}

if(is.null(opt[["dbname"]])&&!opt[["reuse_abc"]])
{
byedie("Please provide the name of the reference database you wish to search against.\nYou can use -l switch to list pre-formatted database versions.\n")
}

if(!file.exists(paste0(opt[["userdir"]],"/db_inventory.txt")))
{
byedie(paste0("Could not find a database inventory file at ",'\"',opt[["userdir"]],'\".',"\n"," Please check that you have locally installed reference database and the path is accurate!"))
}else{
db.info=read.table(paste0(opt[["userdir"]],"/db_inventory.txt"),as.is=T,head=T)
db.info=db.info[,c("db.Name","db.CRC","db.Loc","date","Format","is.Latest")]
db.info[,"db.Loc"]=paste0(opt[["userdir"]],"/",db.info[,"db.Loc"])
taxdb.loc.sel=db.info[db.info[,"db.Name"]=="ncbi_taxonomy"&db.info[,"is.Latest"]=="yes","db.Loc"]
db.info=db.info[db.info[,"Format"]%in%c("ncbidump",opt[["aligner"]]),]
if(grepl(":",opt[["dbname"]]))
{
db.sel=unlist(strsplit(opt[["dbname"]],":"))
db.loc.sel=db.info[db.info[,"db.Name"]==db.sel[[1]]&db.info[,"db.CRC"]==db.sel[[2]],"db.Loc"]
}else
{
db.loc.sel=db.info[db.info[,"db.Name"]==opt[["dbname"]]&db.info[,"is.Latest"]=="yes","db.Loc"]
}
}
if (opt[["list_databases"]])
{
cat("Listing pre-formatted reference databases.\n")
db.info.s=split(db.info,db.info[,"db.Name"])
res=lapply(names(db.info.s),function(x) {cat(x,"\n");db.print=db.info.s[[x]];db.print=db.print[,colnames(db.print)!="db.Loc"];print_screen(hux(db.print),colnames=FALSE)})
q(save="no",status=0)
}
DropTax=tolower(unlist(strsplit(opt[["exclude_tax"]],"\\|")))

if(!all(DropTax%in%c("all","viruses","bacteria","archaea","fungi","viridiplantae","metazoa","other_euk","none")))
{
byedie(paste0("Please provide taxons to be filtered!\nAccepted categories: [all|viruses|bacteria|archaea|fungi|viridiplantae|metazoa|other_euk|none]\nYou can provide multiple keywords at once, separated by \"|\". Example: -x archaea|bacteria\n"))
}

if(is.null(opt[["querytax"]])){
byedie(paste0('Please provide an NCBI Taxon ID for the query genome via option -q!'))
}else if(!grepl("^\\d+$",opt[["querytax"]]))
{
byedie(paste0('Please ensure the NCBI Taxon ID only contains numeric characters!'))
}

protfile=list.files(paste0("FASTA_prot"),full.name=T)
protfile=grep("(\\.fa\\.*g*z*$|\\.faa.*g*z*$|\\.fasta.*g*z*$)",protfile,value=T,ignore.case=T)
if(!length(protfile)==1)
{
byedie(paste0('Please create a folder named "FASTA_prot" within ',opt[["inputdir"]]," and copy your protein fasta file there.\nPlease note that only one protein file is allowed per run."))
}
if(!opt[["no_annot"]])
{
annotfile=list.files(paste0("GFF_annot"),full.name=T)
annotfile=grep("\\.g[tf]f3*\\.*g*z*$",annotfile,value=T,ignore.case=T)
if(!length(annotfile)==1)
{
byedie(paste0('Please create a folder named "GTF_annot" within ',opt[["inputdir"]]," and copy your annotation file there.\nPlease note that only one protein file is allowed per run."))
}
}else{
info("Option -n active, run is carried out witout an annotation file.\nEach protein will be assigned into virtual singleton contig.\n")
}

q.tax.cmd=paste0("grep ",opt[["querytax"]]," ",taxdb.loc.sel)
q.tax.hit=system(q.tax.cmd,intern=T)
q.tax.hit=grep(paste0("^",opt[["querytax"]],"\\t"),q.tax.hit,value=T)

if(length(q.tax.hit)!=1)
{
byedie(paste0('Could not link TaxonID "',opt[["querytax"]],'" to a single taxon tag within the Taxon Database. It is either missing or present in multiple copies.'))
}else{
 q.tax.hit=gsub("\\t\\|$","",q.tax.hit)
 tax.last=gsub("^.+\\t","",q.tax.hit)
 tax.first=gsub(" ","_",gsub("\\t\\|\\t.+$","",gsub("^\\d+\\t\\|\\t","",q.tax.hit)))
 tax.first=gsub("[\\*,\\/,\\\\,\\',?,\\^,\\$,\\@,\\#,\\`,\\,\\>,\\<,\\:,\\&,\\{,\\},\\),\\(,\\!,\\+,\\=,\\%,\\ ́,\\ ̌,\\;]","_",tax.first) #remove chars from taxon name that would mess up folder name when used as part of outdir
 tax.first=gsub('\"',"_",tax.first)
 tax.first=gsub("(\\[|\\])","",tax.first)
 tax.first=gsub("_+","_",tax.first)
 if(tax.last%in%c("Archaea","Bacteria","Viruses"))
  {
  q.tax.tag=tax.last
  }else if(tax.last=="Eukaryota"){
   tax.euk2=unlist(strsplit(q.tax.hit,"\\t\\|\\t"))[[9]]
   if(tax.euk2=="")
    {q.tax.tag="Other_eukaryote"}else{q.tax.tag=tax.euk2}
  }else{
byedie("The provided TaxonID was not found within Archaea, Bacteria or Eukarota.")
}
}

now.stamp = paste0(tax.first,"_tax_",opt[["querytax"]],"_",format(time_start,"%d%b_%Y_%H_%M"))
#now.stamp=""Salpingoeca_rosetta(tax_946362)_15Jun_2022_15_26"

outdir=paste0(now.stamp)
if(!file.exists(outdir))
{dir.create(outdir)}

opt[["outdir"]]=outdir

saveRDS(opt,paste0(outdir,"/Arguments.RDS"))
close(logfile) #we close log file and move it to outdir folder
rf=file.rename(logfilename,paste0(outdir,"/",logfilename))
logfile=file(paste0(outdir,"/",logfilename),open="a") 

info(paste0("Analysis started at ",time_start),log=T)
info(paste0("Command: ",paste(cargs,collapse=" ")),log=T)
info("Databases found:",log=T)
info(readLines(paste0(opt[["userdir"]],"/db_inventory.txt")),log=T)

q.tax.tag=tolower(q.tax.tag)
cpu_info=system("lscpu",intern=T)
numT=grep('Thread(s) per core:',cpu_info,fixed=T,value=T)
numT=as.numeric(gsub("^.+\\s","",numT))
numC=grep("^CPU\\(s\\):",cpu_info,value=T)
numC=as.numeric(gsub("^CPU\\(s\\):\\s+","",numC))
numC_max=numC/numT
#number of physical cores. IGNORE hyperthreading
if(opt[["cpu"]]=="all")
{
opt[["cpu"]]=numC_max
} else if(as.numeric(opt[["cpu"]])>as.numeric(numC_max))
{
info(paste0("System only has ",numC_max, " CPUs installed. Decreasing -c value accordingly.\n"),log=T)
opt[["cpu"]]=numC_max
}

cat("Now reading fasta headers file.\n")
if(grepl("\\.gz$",protfile)){
input.headers=gsub(">","",system(paste0('zgrep ">" ',protfile),intern=T))
}else{
input.headers=gsub(">","",system(paste0('grep ">" ',protfile),intern=T))
}
input.headers=gsub(" .+","",input.headers) #remove any extra info from fasta headers beyond space character

dir.create(paste0(outdir,"/FASTA_prot"))
copyres=file.copy("FASTA_prot",paste0(outdir),recursive=T)

if(!opt[["no_annot"]]){
cat("Now reading annotation file.\n")
GFF=readGFF(annotfile)
prot_ID_column=grep("^protein_*id$",colnames(GFF),ignore.case=T,value=T) #understands proteinID protein_ID in any capitalization
if(length(prot_ID_column)!=1)
{
byedie("Error found in annotation file. After GFF import, there should be exactly one \"protein_id\" column present.\nExiting...\n")
}
GFF.sel=data.frame(GFF[GFF[,prot_ID_column]%in%input.headers,c("seqid",prot_ID_column)],stringsAsFactors=F)
if(nrow(GFF.sel)==0)
{
byedie("Error! Protein IDs in the protein sequence file completely differ from the IDs used in the GFF file.\nExiting...\n")
}
GFF.sel.s=split(GFF.sel,GFF.sel[,prot_ID_column]) 
MultiCtgProts=unlist(mclapply(GFF.sel.s,function(x) return(length(unique(x[,"seqid"]))>1),mc.cores=opt[["cpu"]]))
MultiCtgProts=names(MultiCtgProts)[MultiCtgProts]
gene.contig=unlist(mclapply(GFF.sel.s,function(x) return(unique(as.character(x[,"seqid"]))),mc.cores=opt[["cpu"]]))
GhostProts=setdiff(input.headers,names(gene.contig))
writeLines(GhostProts,"GhostProteins.txt")
if(!opt[["force"]])
{
if(length(GhostProts)>0) #what about multi-mapper proteins?
{
byedie(paste0("Inconsistent annotation found:\n",length(setdiff(input.headers,names(gene.contig)))," out of ",length(input.headers)," proteins are missing from the annotation file.\nRefusing to work with inconsistent annotation data...\nPlease repair the GTF annotation file or use the -f switch to force the analysis.\nIf you continue with the invaluid GFF, all unmapped proteins will be flagged\nand removed regardless to their taxon flags.\n"))
}
}else
{
info("Switch -f / --force active. We will ignore inconsistent annotation.\nPlease note that any protein that has no record in the annotation will be removed.\n")
}
if(!opt[["force"]])
{
if(any(MultiCtgProts)) 
{
byedie(paste0("Inconsistent annotation found:\n",sum(MultiCtgProts)," out of ",length(input.headers)," proteins belong to multiple contig.\nRefusing to work with inconsistent annotation data...\nPlease repair the GTF annotation file or use the -f switch to force the analysis.\nIf you continue with the invaluid GFF,proteins mapping to multiple contigs will not be tested.\n"))
}
}else
{
info("Switch -f / --force active. We will ignore inconsistent annotation.\nPlease note that any protein that is linked to multiple contigs will not be checked.\n")
}
ctgDB=cbind(names(gene.contig),gene.contig)
ctgDB=data.frame(ctgDB,stringsAsFactors=F)
colnames(ctgDB)=c("ProteinID","Contig")
rownames(ctgDB)=NULL
dir.create(paste0(outdir,"/GFF_annot"))
copyres=file.copy("GFF_annot",outdir,recursive=T)
}else
{
info("Found -n / --no_annot switch. Creating a virtual contig database linking each protein as a singleton.\nThat way, proteins are evaluated one by one.\nProteins from HGT events are likely to be tagged as contamination when using this switch.\n")
ctgDB=matrix(ncol=2,nrow=length(input.headers))
colnames(ctgDB)=c("ProteinID","Contig")
ctgDB[,"Contig"]=paste0("NullCtg_",1:length(input.headers))
ctgDB[,"ProteinID"]=input.headers
ctgDB=data.frame(ctgDB,stringsAsFactors=F)
ctgDB=split(ctgDB,ctgDB[,"Contig"])
GhostProts=""
}
saveRDS(ctgDB,paste0(outdir,"/ContigDB.RDS"))
run_alignment=TRUE

if(opt[["reuse_abc"]])
{
#check if ABC file is present and we want to use it
if(file.exists("ABC.s.RDS")&&file.exists("ABC.s.md5sum")&&file.info("ABC.s.md5sum")[,"size"]>0){
ABC.saved.md5=readLines("ABC.s.md5sum")
ABC.saved.md5=substr(ABC.saved.md5,1,32)
ABC.check.md5=system("md5sum ABC.s.RDS",intern=T)
ABC.check.md5=substr(ABC.check.md5,1,32)
if(ABC.check.md5==ABC.saved.md5)
{
info("Alignment R Data file from previous run was found intact. Re-using it as requested.\n")
run_alignment=FALSE
cat("Now reading Alignment result (ABC) file.\n")
ABC.s=readRDS("ABC.s.RDS")
}else{
info("MD5 signature mismatch. Alignment R Data file from previous run seems to be corrupt. Repeating the entire alignment step.\n")
}
}else{
info("MD5 signaure for ABC file is missing. Repeating the entire alignment step.\n")
}
}

#MMSeqs prep and run#create MMSeqs database
if(run_alignment)
{
if(opt[["aligner"]]=="mmseqs")
{
#CPU type
cpu=grep("Flags:",system("lscpu",intern=T),value=T)
if(grepl(" avx2 ",cpu)){
mmseqs.bin="mmseqs_avx2"
} else if (grepl(" sse4_1 ",cpu)) {
mmseqs.bin="mmseqs_sse41"
} else {
mmseqs.bin="mmseqs_sse2"
}
qdb=gsub("(\\.fa|\\.faa|\\.fasta).*g*z*$",".db",protfile)
qdb=gsub(".+/","",qdb)
MM.qdb.cmd=paste0(mmseqs.bin," createdb ",protfile," ",outdir,"/",qdb)
cat("Converting query sequences to MMSeqs database format\n")
system(MM.qdb.cmd)

##perform MMSeqs search
MM.search.cmd=paste0(mmseqs.bin," search -s ",opt[["sens"]]," -a --threads ",opt[["cpu"]]," ",outdir,"/",qdb," ",db.loc.sel," ",outdir,"/TaxMMSeqs.resDB"," ",opt[["tmpdir"]])
if(!is.null(opt[["memlimit"]]))
{
MM.search.cmd=paste0(MM.search.cmd," --split-memory-limit ",opt[["memlimit"]])
}
MM.search.cmd=paste0(MM.search.cmd," >",outdir,"/mmseqs.log 2>",outdir,"/mmseqs.error" )

info(paste0("Search command:\n",MM.search.cmd,"\n"))

system(MM.search.cmd)
Trafo.cmd=paste0(mmseqs.bin," convertalis ",outdir,"/",qdb," ",db.loc.sel," ",outdir,"/TaxMMSeqs.resDB"," ",outdir,"/TaxMMSeqs.ABC --format-output query,target,bits,qlen,nident --threads ",opt[["cpu"]])
system(Trafo.cmd)
}else if (opt[["aligner"]]=="diamond"){
#perform DIAMOND search
DM.search.cmd=paste0("diamond blastp -d ",db.loc.sel," -q ",protfile," -o ",outdir,"/TaxMMSeqs.ABC -f 6 qseqid sseqid bitscore qlen nident --threads ", opt[["cpu"]])
if(!is.null(opt[["memlimit"]]))
{
DM.search.cmd=paste0(DM.search.cmd," --memory-limit ",gsub("G$","",opt[["memlimit"]]))
}
info(paste0("Search command:\n",DM.search.cmd,"\n"))
system(DM.search.cmd)
}


cat("Now reading Alignment result (ABC) file.\n")
ABC=read.table(paste0(outdir,"/TaxMMSeqs.ABC"),sep="\t",as.is=T) 
colnames(ABC)=c("Q","H","BS","Qlen","Nident")
ABC[,"H"]=gsub("\\|(TaxID|RepID):",":",ABC[,"H"])
ABC[,"QPCI"]=ABC[,"Nident"]/ABC[,"Qlen"]*100
ABC=ABC[ABC[,"QPCI"]>=opt[["pci"]],]
ABC=ABC[!grepl(":NA$",ABC[,"H"]),] #drop uninformative hits with NA as taxon ID.
ABC.s=split(ABC,ABC[,"Q"])
ABC.s=mclapply(ABC.s,function(x) return(x[order(-x[,"QPCI"]),]),mc.cores=opt[["cpu"]])
ABC.s=mclapply(ABC.s,function(x) {x[,"Q.TaxID"]=paste0("t",opt[["querytax"]]);x[,"Q.TaxTag"]=q.tax.tag;x[,"H.TaxID"]=sapply(x[,"H"],function(z) return(unlist(strsplit(z,":"))[2]));x[,"H.TaxTag"]=sapply(x[,"H"],function(z) return(unlist(strsplit(z,":"))[3]));return(x[x[,"Q.TaxID"]!=x[,"H.TaxID"],])},mc.cores=opt[["cpu"]])
ABC.s=lapply(ABC.s,function(x) head(x,n=100))
saveRDS(ABC.s,paste0(outdir,"/ABC.s.RDS"))
system(paste0("md5sum ",outdir,"/ABC.s.RDS >",outdir,"/ABC.s.md5sum"))
}

cat("Classifying individual proteins.\n")
ABC.AllVoteSame=sapply(ABC.s,function(x) length(unique(x[,'H.TaxTag']))==1) #2852 / 530 T

info(paste0("All_vote_same T/F:",paste(as.character(summary(factor(ABC.AllVoteSame,levels=c(TRUE,FALSE)))),collapse="/"),".\n"))

ABC.decided=ABC.s[ABC.AllVoteSame]
ABC.decided.6plus=names(ABC.decided)[sapply(ABC.decided,function(x) nrow(x)>=6)]
ABC.undecided=ABC.s[!ABC.AllVoteSame]
ABC.undecided.OK=sapply(ABC.undecided,function(x) nrow(x)>=3)
ABC.undecided=ABC.undecided[ABC.undecided.OK]
cut_dynRLE=function(x)
{
NR_taxRLE=Rle(x[,"H.TaxTag"])
num_tax_levels=sapply(1:length(runValue(NR_taxRLE)),function(x) length(unique(runValue(NR_taxRLE)[1:x])))
cutdown=max(which(num_tax_levels<3))
cutdown=min(cutdown,4) #if two tags alterates, limit the number of transitions to 3 (meaning 4 runs maximum!)
element_cutdown=sum(runLength(NR_taxRLE)[1:cutdown])
return(x[1:element_cutdown,"H.TaxTag"])
}

RLE_data=mclapply(ABC.undecided,FUN=cut_dynRLE,mc.cores=opt[["cpu"]])
RLE_scores=unlist(mclapply(RLE_data,function(x) if(length(x)>=6){return(2)}else{return(1)},mc.cores=opt[["cpu"]]))
gimme_UD_tax=function(x)
{
x.slr=sapply(split(x,x),function(x) length(x))/length(x)
x.slr.sel=x.slr[x.slr>=0.66]
if(length(x.slr.sel)>0)
{
return(names(x.slr.sel))
}else{return("ambig")}
}

RLE_taxonNames=unlist(mclapply(RLE_data,FUN=gimme_UD_tax,mc.cores=opt[["cpu"]]))
RLE_scores[RLE_taxonNames=="ambig"]=0.001
RLE_table=data.frame(cbind(RLE_taxonNames,RLE_scores,"dynRLE"),stringsAsFactors=F)
colnames(RLE_table)=c("TaxTag","Score","Decision")
Uniform_table=data.frame(cbind(sapply(ABC.decided,function(x) x[1,"H.TaxTag"]),"1","UniVote"),stringsAsFactors=F)
colnames(Uniform_table)=c("TaxTag","Score","Decision")
Uniform_table[rownames(Uniform_table)%in%ABC.decided.6plus,"Score"]=2
Combined_table=rbind(RLE_table,Uniform_table)
Nodata_ID=setdiff(input.headers,rownames(Combined_table))
Nodata_table=data.frame(matrix(rep(c("NoData","0.001","NoData"),each=length(Nodata_ID)),ncol=3),stringsAsFactors=F)
rownames(Nodata_table)=Nodata_ID
colnames(Nodata_table)=c("TaxTag","Score","Decision")

Combined_table=rbind(Combined_table,Nodata_table)
Combined_table[,"TaxTag"]=tolower(Combined_table[,"TaxTag"])
if(!all(rownames(Combined_table)%in%input.headers))
{
byedie("Data corruption found in Combined Table. That sux hard!")
}
saveRDS(Combined_table,paste0(outdir,"/ProteinTaxDB_ContScout.RDS"))
protsum=summary(factor(Combined_table[,"TaxTag"]))
protsum=cbind(names(protsum),protsum)
colnames(protsum)=c("TaxTag","NProt")
protsum=protsum[order(-as.numeric(protsum[,"NProt"])),]
protsum2=apply(protsum,1,function(x) paste0(x[[1]],"\t",x[[2]]))
protsum2=c("Protein tag summary:\n","TaxTag\tNprot",protsum2)
cat("Protein tag summary:\n","TaxTag\tNprot\n")
print_screen(hux(protsum))
writeLines(protsum2,con=logfile)
#check for no data. Throw warning, if % no data is high!
if("nodata" %in% protsum[,"TaxTag"]&&as.numeric(protsum["nodata","NProt"])>=0.5*sum(as.numeric(protsum[,"NProt"])))
{
info("Warning: CountScout failed to assign taxonomy tag for more than 50% of query proteins.\n")
}
if(opt[["no_annot"]]){ctgDB=do.call(rbind,ctgDB)}
no_ctg_prot=setdiff(rownames(Combined_table),ctgDB[,"ProteinID"])
if(length(no_ctg_prot)>0)
{
byedie("Protein without contig information found. That should not happen at this point.")
}
no_tax_data=setdiff(ctgDB[,"ProteinID"],rownames(Combined_table))
if(length(no_tax_data)>0)
{
info("Warning: Some protein with contig information lacks Taxon classification info.\nThis might indicate conflict between annotation and protein file.\nAffected proteins will be handled as no_data.\n")
tax_addon_df=data.frame(matrix(NA,nrow=length(no_tax_data),ncol=3))
rownames(tax_addon_df)=no_tax_data
colnames(tax_addon_df)=c("TaxTag","Score","Decision")
tax_addon_df[,"TaxTag"]="nodata"
tax_addon_df[,"Decision"]="nodata"
tax_addon_df[,"Score"]=0.001
Combined_table=rbind(Combined_table,tax_addon_df)
}
Combined_table[,"ProteinID"]=rownames(Combined_table)
#prepare for multi-mapper proteins! use merge here
Combined_table=merge(Combined_table,ctgDB,by="ProteinID") #watch out for x.all, y.all switches
Combined_table.s=split(Combined_table[,c("TaxTag","Score")],Combined_table[,"Contig"])
Combined_table.nprot=sapply(Combined_table.s,function(x) nrow(x))
Combined_table.s=mclapply(Combined_table.s,function(x) return(split(x[,"Score"],x[,"TaxTag"])),mc.cores=opt[["cpu"]])
protTaxDB.sum=mclapply(Combined_table.s,function(x) sapply(x,function(y) sum(as.numeric(as.character(y)))),mc.cores=opt[["cpu"]])

calc_score_ratios=function(x)
{
x.s=sum(x)
x.r=round(x/x.s,digits=2)
x.r=x.r[x.r>0]
return(x.r)
}

CTG_TaxCalls=mclapply(protTaxDB.sum,FUN=calc_score_ratios,mc.cores=opt[["cpu"]])
CTG_TaxCalls=mclapply(CTG_TaxCalls,function(x) return(names(x)[x>=2/3]),mc.cores=opt[["cpu"]])
CTG_TaxCalls[sapply(CTG_TaxCalls,function(x) length(x)==0)]="undecided"
CTG_TaxCalls=unlist(CTG_TaxCalls)
CTG_TaxCalls=cbind(names(CTG_TaxCalls),CTG_TaxCalls,Combined_table.nprot)
CTG_TaxCalls=data.frame(CTG_TaxCalls,stringsAsFactors=T)
colnames(CTG_TaxCalls)=c("Contig","ContigTax","NumProt")

Combined_table2=merge(Combined_table,CTG_TaxCalls,by="Contig")
Combined_table2[,"outID"]=paste0(Combined_table2[,"ProteinID"]," ProtTag:",Combined_table2[,"TaxTag"],"|ContigTag:",Combined_table2[,"ContigTax"],"|CtgNumProt:",Combined_table2[,"NumProt"])
rownames(Combined_table2)=Combined_table2[,"ProteinID"]

CTG_TaxCalls_sum=split(as.numeric(as.character(CTG_TaxCalls[,"NumProt"])),CTG_TaxCalls[,"ContigTax"])
CTG_TaxCalls_sumsum=sapply(CTG_TaxCalls_sum,function(x) sum(x))
CTG_TaxCalls_sumsum_called=CTG_TaxCalls_sumsum[!names(CTG_TaxCalls_sumsum)%in%c("undecided","ambig","nodata")]

CTG_TaxCalls_Mat=data.frame(matrix(NA,ncol=3,nrow=length(CTG_TaxCalls_sum)),stringsAsFactors=F)
colnames(CTG_TaxCalls_Mat)=c("Call","NumCtg","NumTotalProt")
CTG_TaxCalls_Mat[,"Call"]=names(CTG_TaxCalls_sum)
CTG_TaxCalls_Mat[,"NumCtg"]=sapply(CTG_TaxCalls_sum,function(x) length(x))
CTG_TaxCalls_Mat[,"NumTotalProt"]=sapply(CTG_TaxCalls_sum,function(x) sum(x))
ctgTagsum2=apply(CTG_TaxCalls_Mat,1,function(x) paste0(x[[1]],"\t",x[[2]],"\t",x[[3]]))
ctgTagsum2=c("\nContig-based tag summary on all proteins:\n","CtgBasedTag\tNCtg\tNProts",ctgTagsum2)
info(ctgTagsum2)


if("undecided"%in%names(CTG_TaxCalls_sumsum)&&CTG_TaxCalls_sumsum[["undecided"]]/sum(CTG_TaxCalls_sumsum)>=0.33){
info(paste0("Warning! Too many proteins (",round(CTG_TaxCalls_sumsum[["undecided"]]/sum(CTG_TaxCalls_sumsum)*100,digits=0),"%) belong to ambiguous contigs.","\n","This might indicate assembly error, scaffolding error or genomes that are heterogenous (some protists).","\n",
"Protein filtering results are likely to be inaccurate for this query genome!","\n"))
} else if (!q.tax.tag%in%names(CTG_TaxCalls_sumsum_called) || CTG_TaxCalls_sumsum_called[[q.tax.tag]]/sum(CTG_TaxCalls_sumsum_called)<0.5)
{
info(paste0('Warning! Less than 50% of the classified query proteins are located on "',q.tax.tag,'"'," contigs.\n"))
info(paste0("This can indicate a massive contamination, or an invalid query taxon value! (Input: ",opt["querytax"],",",q.tax.tag,").\n"))
}
if(any(DropTax=="all"))
{
DropCTG=CTG_TaxCalls[!CTG_TaxCalls[,"ContigTax"]%in%c("undecided","nodata","ambig",q.tax.tag),]
}else{
DropCTG=CTG_TaxCalls[CTG_TaxCalls[,"ContigTax"]%in%DropTax,]
}



saveRDS(DropCTG,paste0(outdir,"/DropContig.RDS")) #scaffold_172, scaffold_279 Bjead1_1_124264, Bjead1_1_98652
DropProts=unique(Combined_table2[as.character(Combined_table2[,"Contig"])%in%as.character(DropCTG[,"Contig"]),"ProteinID"]) 
saveRDS(DropProts,paste0(outdir,"/DropProts.RDS"))
#here comes stats, and dropseq labeling
suppressPackageStartupMessages(library("Biostrings"))
d=readAAStringSet(protfile)
names(d)=gsub(" .+$","",names(d))
GhostProteinDB=d[names(d)%in%GhostProts]
writeXStringSet(GhostProteinDB,paste0(opt[["outdir"]],"/Ghost.ProteinSeq.faa"))

d2=d[!names(d)%in%DropProts]
d.drop=d[names(d)%in%DropProts]
names(d.drop)=Combined_table2[names(d.drop),"outID"]


drop_prot_calls=gsub("^.+ProtTag:","",gsub("\\|.+$","",names(d.drop)))
drop_ctg_calls=gsub("\\|.+$","",gsub("^.+ContigTag:","",names(d.drop)))

protTagsum=summary(factor(drop_prot_calls))
protTagsum=cbind(names(protTagsum),protTagsum)
colnames(protTagsum)=c("TaxTag","NProt")
protTagsum=data.frame(protTagsum,stringsAsFactors=F)
protTagsum=protTagsum[order(-as.numeric(protTagsum[,"NProt"])),]
protTagsum2=apply(protTagsum,1,function(x) paste0(x[[1]],"\t",x[[2]]))
protTagsum2=c("\nProtein tag summary on removed proteins:\n","ProtTaxTag\tNprots",protTagsum2)
info(protTagsum2)

dropCTG_TaxCalls_sum=split(as.numeric(as.character(DropCTG[,"NumProt"])),DropCTG[,"ContigTax"])

dropCTG_TaxCalls_Mat=data.frame(matrix(NA,ncol=3,nrow=length(CTG_TaxCalls_sum)),stringsAsFactors=F)
colnames(dropCTG_TaxCalls_Mat)=c("Call","NumCtg","NumTotalProt")
dropCTG_TaxCalls_Mat[,"Call"]=names(dropCTG_TaxCalls_sum)
dropCTG_TaxCalls_Mat[,"NumCtg"]=sapply(dropCTG_TaxCalls_sum,function(x) length(x))
dropCTG_TaxCalls_Mat[,"NumTotalProt"]=sapply(dropCTG_TaxCalls_sum,function(x) sum(x))
ctgTagsum2=apply(CTG_TaxCalls_Mat,1,function(x) paste0(x[[1]],"\t",x[[2]],"\t",x[[3]]))
ctgTagsum2=c("\nContig-based tag summary on all proteins:\n","CtgBasedTag\tNCtg\tNProts",ctgTagsum2)
info(ctgTagsum2)

info("Checking inconsistency between DropProt list and Contamination sequence file.")
issue=setdiff(DropProts,gsub(" .+$","",names(d.drop)))
if(length(issue)==0)
{
info("No inconsistency between DropProt and Contamination sequence file found.\n")
}else{
info("The following mismatch between DropProt and Contamination sequence file was found:\n")
info(paste(issue,collapse="\n"))
}

writeXStringSet(d2,paste0(opt[["outdir"]],"/Cleaned.ProteinSeq.faa"))
writeXStringSet(d.drop,paste0(opt[["outdir"]],"/Contamination.ProteinSeq.faa"))
info("Contscount finished.\n")
time_finish=Sys.time()
timediff=time_finish-time_start
print(timediff)
info(paste0("Time (minutes) passed: ",round(as.numeric(timediff,unit="mins"),digits=0)))
close(logfile)

