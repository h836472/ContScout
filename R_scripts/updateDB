#!/usr/bin/Rscript

###########################
#library and arguments init
###########################
progname="updateDB"
cat("This is the database updater component of ContScout.\n")
cat("Loading R libraries.\n") 
suppressPackageStartupMessages(library("optparse"))
suppressPackageStartupMessages(library(parallel))
suppressPackageStartupMessages(library(rjson))
suppressPackageStartupMessages(library(XML))

option_list = list(
make_option(c("-u", "--userdir"), type="character", default=NULL, 
              help="Path to local database repository folder", metavar="userdir"),
make_option(c("-d", "--dbname"), type="character", default=NULL,
                help='Database to download ("uniprot","uniref100","nr","refseq_protein")', metavar="dbname"),
make_option(c("-i", "--info"), type="character", default="https://github.com/h836472/ContScout/raw/main/DataBaseInfo/DB.info.txt",
                help='Database info file with public database URLs', metavar="info"),
make_option(c("-c", "--cpu"), type="integer", default=0,
                help='Number of CPU-s to use. By default (-c 0) we use all CPUs available.', metavar="cpu"),
make_option(c("f", "--format"), type="character", default="DM", 
                help='Which database format to use (D for Diamond, M for MMSeqs).', metavar="FORMAT"),
make_option(c("-l", "--localDB"), type="character", default=NULL,
              help="Local mirror folder to download databases from. For development / testing only.", metavar="localDB"),
make_option(c("-y", "--yes"), action="store_true", default=FALSE,
              help="Automatically answer yes to all question. Enables batch database download.", metavar="yes"));

opt_parser = OptionParser(option_list=option_list,prog=progname);
if(FALSE)
{
#manually set options, if you run the code interactively, for debugging/development
opt=list()

opt[["dbname"]]="uniprotSP" #-d
opt[["cpu"]]=8 #-c 
opt[["format"]]="DM" #-f
opt[["localDB"]]=TRUE #-l
opt[["yes"]]=FALSE #-y

#Perlmutter
opt[["userdir"]]="/pscratch/sd/b/balintb/databases_dev" #-u
opt[["info"]]="/pscratch/sd/b/balintb/databases.dev/dbinfo.txt" #-i

#komondor
opt[["userdir"]]="/home/g6y1acd/databases_dev" #-u
opt[["info"]]="/home/g6y1acd/databases.dev/dbinfo.txt" #-i



}else{
opt = parse_args(opt_parser);
}

###############################
#URL data init from -i (--info)
###############################


#download public database URL information from GitHub repository or open from local file

if(grepl("^http",opt[["info"]])){
DBinfo=read.table(url(opt[["info"]]),sep=",",as.is=T,row.name=1,header=T)
}else
{
DBinfo=read.table(opt[["info"]],sep=",",as.is=T,row.name=1,header=T)
}


###################################
#generic logging and info functions
###################################
byedie=function(x,log=TRUE,sure_q=TRUE){
cat(x)
if(log)
 {
 writeLines(x,con=logfile)
 }
if(sure_q)
 {
 q(save="no",status=1)
 }else
 {
 cat("\nFatal error found but quit cancelled by sure_q=FALSE...\n")
 }
}

info=function(x,log=T){
cat(paste(x,"\n"))
if(log)
 {
 writeLines(x,con=logfile)
 }
}

jacksum=function(x)
{
crc=system(paste0("jacksum -a crc32 -E hex ",x),intern=T)
return(gsub("\\s.+$","",crc[length(crc)]))
#issue with container: jacksum output might contain an suprplus line with a weird warning, poisoning checksum. Oh yeah! :)
}

log_DB_add=function(x,db,string)
{
string=matrix(unlist(strsplit(string,"_#_")),nrow=1)
string=data.frame(string,stringsAsFactors=F)
colnames(string)=c("db.Name","info.File","info.MD5","db.CRC","db.Loc","db.Version","nProt","annotTaxDB","date","Format","is.Latest")
if(file.exists(x)&&file.info(x)$size>0)
{
dbi.t=read.table(x,sep="\t",as.is=T,quote='"',header=T) #database, #folder, #fasta,#numprot #MD5, #jacksum
dbi.t[dbi.t[,"db.Name"]==db,"is.Latest"]="no"
dbi.new=rbind(dbi.t,string)
}else
{dbi.new=string
}
write.table(dbi.new,x,quote=T,row.names=F,col.names=T,sep="\t")
}

##########################


##AUX functions#######
create.dir=function(x){
#place the system call in a function to enable error checking
dir.create(x)
}

user.input = function(prompt) {
  if (interactive()) {
    return(readline(prompt))
  } else {
    cat(prompt)
    return(readLines("stdin", n=1))
  }
}
#####################################################
#MAIN SCRIPT START HERE, with Initial error checking#
#####################################################

startdir=getwd()
time_start=Sys.time()
logfilename=paste0("CS_DatabaseUpdater_",format(time_start,"%d%b_%Y_%H_%M"),".log")
logfile=file(logfilename,open="a") 

#detect num CPU
numC_max=as.numeric(system("lscpu -b -p=Core,Socket | grep -v '^#' | sort -u | wc -l",intern=T)) #determine the number of physical cores in the system. Effect od hyperthreading is ignored! 

#CPU type, mmseqs binary
cpu=grep("Flags:",system("lscpu",intern=T),value=T)
if(grepl(" avx2 ",cpu)){
mmseqs.bin="mmseqs_avx2"
} else if (grepl(" sse4_1 ",cpu)) {
mmseqs.bin="mmseqs_sse41"
} else {
mmseqs.bin="mmseqs_sse2"
}


#set numCPU
if(opt[["cpu"]]==0)
{
opt[["cpu"]]=numC_max
}else if(opt[["cpu"]]>numC_max){
opt[["cpu"]]=numC_max
}
opt[["IO_cpu"]]=min(opt[["cpu"]],8)
info(paste0("Using ",opt[["cpu"]]," CPUs for general tasks and ",opt[["IO_cpu"]]," CPUs for IO operations.\n"))


opt[["dbname"]]=match.arg(opt[["dbname"]],c("ncbi_taxonomy","nr_prot","refseq_prot","uniprotKB","uniref100","swissprot","uniprotSP"))


if(!("ncbi_taxonomy"%in%rownames(DBinfo) && opt[["dbname"]]%in% rownames(DBinfo)))
{
byedie(paste0("Data from info file \'",opt[["info"]],"\' is incomplete.\nSome required database URL is missing!\n"))
}

if(is.null(opt[["userdir"]]))
{
stop("Please set your local database directory with -u or --userdir option!")
}
#Update checker and downloader functions

chk_update=function(wd,sd,what,i)
{
setwd(wd)
timestamp=paste0("update_checker_",format(Sys.time(),"%Y%m%d%H%M"))
dbi.f=paste0(opt[["userdir"]],"/db_inventory.txt")
if(!file.exists(paste0("tmp/",timestamp))){dir.create(paste0("tmp/",timestamp))}

if(!(file.exists(dbi.f)&&file.info(dbi.f)$size>0))
 {
 unlink(paste0("tmp/",timestamp),recursive=T)
 return(TRUE)
 }else
 {
 dbi.t=read.table(dbi.f,sep="\t",as.is=T,header=T,quote='"') 
 dbi.t=dbi.t[dbi.t[,"is.Latest"]=="yes",] #keep only latest versions
 rownames(dbi.t)=dbi.t[,"db.Name"]
 dbi.t=dbi.t[what,]
 }
db_desc_URL=i[what,"DB_URL"]
md5.download.cmd=paste0("wget --no-check-certificate ",db_desc_URL," -O tmp/",timestamp,"/",what,"_info.txt")
system(md5.download.cmd)
info.refmd5=substr(system(paste0("md5sum tmp/",timestamp,"/",what,"_info.txt"),intern=T),1,32)
unlink(paste0("tmp/",timestamp),recursive=T)
return(!(!is.na(dbi.t[what,"info.MD5"])&&(info.refmd5==dbi.t[what,"info.MD5"] && file.exists(dbi.t[,"db.Loc"]))))
#TRUE returned means "update is needed"
#cases: there is no local copy from required DB (is.na)
#info file MD5 does not match local copy 
#local db file is lost
}

dl.ncbi_tax=function(wd=opt[["userdir"]],sd=startdir)
{
setwd(wd)
if(chk_update(wd=opt[["userdir"]],sd=workdir,what="ncbi_taxonomy",i=DBinfo))
{
cat("Fetching NCBI taxonomy database.\n")
timestamp=paste0("ncbi_taxonomy","_",format(Sys.time(),"%Y%m%d%H%M"))
if(!dir.exists(opt[["userdir"]]))
{
dir.create(opt[["userdir"]])
}
if(!dir.exists(paste0(opt[["userdir"]],"/tmp")))
{
dir.create(paste0(opt[["userdir"]],"/tmp"))
}
if(!dir.exists(paste0(opt[["userdir"]],"/ncbi_taxonomy")))
{
dir.create(paste0(opt[["userdir"]],"/ncbi_taxonomy"))
}

dir.create(paste0("tmp/",timestamp))
md5.download.cmd=paste0("wget --no-check-certificate ",DBinfo["ncbi_taxonomy","DB_URL"]," -O tmp/",timestamp,"/new_taxdump.tar.gz.md5")
db.download.cmd=gsub("new_taxdump.tar.gz.md5","new_taxdump.tar.gz",md5.download.cmd)
system(md5.download.cmd)
system(db.download.cmd)
taxdump.md5=substr(system(paste0("md5sum tmp/",timestamp,"/new_taxdump.tar.gz"),intern=T),1,32)
taxdump.refmd5=substr(readLines(paste0("tmp/",timestamp,"/new_taxdump.tar.gz.md5")),1,32)
info.md5=substr(system(paste0("md5sum tmp/",timestamp,"/new_taxdump.tar.gz.md5"),intern=T),1,32)
if(taxdump.refmd5!=taxdump.md5)
{
byedie(paste0("NCBI taxonomy database failed to download!\nDownload from NCBI failed!"))

}else 
{
system(paste0("tar -xvf tmp/",timestamp,"/new_taxdump.tar.gz -C tmp/",timestamp," rankedlineage.dmp"))
taxdump.crc32=jacksum(paste0("tmp/",timestamp,"/rankedlineage.dmp"))
dir.create(paste0("ncbi_taxonomy/",taxdump.crc32))
file.rename(paste0("tmp/",timestamp,"/rankedlineage.dmp"),paste0("ncbi_taxonomy/",taxdump.crc32,"/",taxdump.crc32,"_rankedlineage.dmp"))
unlink(paste0("tmp/",timestamp),recursive=T)
}
logtext=paste("ncbi_taxonomy",paste0("ncbi_taxonomy/",taxdump.crc32,"/",taxdump.crc32,"_new_taxdump.tar.gz.md5"),info.md5,taxdump.crc32,paste0("ncbi_taxonomy/",taxdump.crc32,"/",taxdump.crc32,"_rankedlineage.dmp"),taxdump.crc32,"NA",taxdump.crc32,Sys.time(),"ncbidump","yes",sep="_#_")
log_DB_add(paste0(opt[["userdir"]],"/db_inventory.txt"),"ncbi_taxonomy",logtext)
setwd(sd)
return(paste0("ncbi_taxonomy/",taxdump.crc32,"/",taxdump.crc32,"_rankedlineage.dmp"))
}else
{
dbi.t=read.table(paste0(opt[["userdir"]],"/db_inventory.txt"),sep="\t",as.is=T,header=T,quote='"') 
 dbi.t=dbi.t[dbi.t[,"is.Latest"]=="yes",] #keep only latest versions
 rownames(dbi.t)=dbi.t[,"db.Name"]
 setwd(sd)
 return(dbi.t["ncbi_taxonomy","db.Loc"])
}
}

dl.ncbi_blastdb=function(wd=opt[["userdir"]],sd=startdir,what,i=DBinfo)
{
setwd(wd)
if(!dir.exists(what))
{
dir.create(what)
}
if(chk_update(wd=opt[["userdir"]],sd=startdir,what="ncbi_taxonomy",i=DBinfo)){
dl.ncbi_tax(wd=opt[["userdir"]],sd=startdir)
}
dbi.t=read.table(paste0(opt[["userdir"]],"/db_inventory.txt"),sep="\t",as.is=T,header=T,quote='"') 
dbi.t=dbi.t[dbi.t[,"is.Latest"]=="yes",] #keep only latest versions
rownames(dbi.t)=dbi.t[,"db.Name"]
taxdump.crc32=dbi.t["ncbi_taxonomy","db.Version"]
info(paste0("Fetching BLAST database \'",what,"\' from NCBI.\n"))
timestamp=paste0(what,"_",format(Sys.time(),"%Y%m%d%H%M"))
dir.create(paste0("tmp/",timestamp))
info_outfile=gsub("^.+/","",i[what,"DB_URL"])
info.download.cmd=paste0("wget --no-check-certificate  ",i[what,"DB_URL"]," -O tmp/",timestamp,"/",info_outfile)
system(info.download.cmd)
info.md5=substr(system(paste0("md5sum tmp/",timestamp,"/",info_outfile),intern=T) ,1,32)
info.data=fromJSON(file=paste0("tmp/",timestamp,"/",info_outfile))
dl.chunks=matrix(ncol=4,nrow=length(info.data$files))
dl.chunks[,1]=paste0("wget --no-check-certificate ",gsub(paste0(info_outfile,"$"),"",i[what,"DB_URL"]))
dl.chunks[,2]=gsub("^.+/","",info.data$files)
dl.chunks[,3]=paste0(" -O tmp/",timestamp,"/")
dl.chunks[,4]=gsub("^.+/","",info.data$files)
dl.commands=apply(dl.chunks,1,function(x) paste(x,collapse=""))
writeLines(dl.commands,paste0(timestamp,".download.sh"))
dl.md5.commands=gsub("\\.tar\\.gz",".tar.gz.md5",dl.commands)
dl.check.md5=lapply(dl.md5.commands,function(x) return(system(x)))

if(!all(unlist(dl.check.md5)==0))
{
byedie(paste0("Download of database \'",what,"\' failed!","\n"))
}
dl.check=lapply(dl.commands,function(x) return(system(x)))
if(!all(unlist(dl.check)==0))
{
byedie(paste0("Download of database \'",what,"\' failed!","\n"))
}
gzf=list.files(pattern="gz$",paste0("tmp/",timestamp),full.name=T)
mdf=list.files(pattern="gz.md5",paste0("tmp/",timestamp),full.name=T)
mdd=lapply(mdf,function(x) readLines(x))
names(mdd)=gsub("\\.md5$","",gsub("^.+/","",mdf))
md5sums.exp=sapply(mdd,function(x) substr(x,1,32))
#check chunk md5sums here
md5sums.obs=mclapply(gzf,function(x) system(paste0("md5sum ",x),intern=T),mc.cores=opt[["IO_cpu"]])
names(md5sums.obs)=gsub("^.+/","",gzf)
md5sums.obs=sapply(md5sums.obs,function(x) substr(x,1,32))
if(!(length(md5sums.obs)==length(md5sums.exp) && all(names(md5sums.exp)==names(md5sums.obs))&& all(md5sums.exp==md5sums.obs)))
{
byedie(paste0("MD5 checksum mismatch, database download error with \'",what,"\'!"))
}
gzf=gzf[length(gzf):1]
lapply(gzf,function(x) system(paste0("tar -xvf ",x," -C tmp/",timestamp)))
setwd(paste0("tmp/",timestamp))
system(paste0('blastdbcmd -dbtype prot -db ',what,' -entry all -outfmt ">%a\t%T\t%t\t%s" >',timestamp,"_dump.fasta")) #lookout! \t is recognized while \n is NOT.
num_prot_out=system(paste0('grep -c ">" ',timestamp,"_dump.fasta"),intern=T)
setwd(opt[["userdir"]])
tax=readLines(dbi.t["ncbi_taxonomy","db.Loc"])
tax=gsub("\\t\\|$","",tax)
tax.last=gsub("^.+\\t","",tax)
tax.simple=tax.last[tax.last%in%c("Archaea","Bacteria","Viruses")]
names(tax.simple)=paste0("t",gsub("\\t.+$","",tax[tax.last%in%c("Archaea","Bacteria","Viruses")]))
tax.euk=tax[tax.last=="Eukaryota"]
tax.euk2=mclapply(tax.euk,function(x) unlist(strsplit(x,"\\t\\|\\t")),mc.cores=opt[["cpu"]])
tax.euk3=sapply(tax.euk2,function(x) x[9])
tax.euk3[tax.euk3==""]="Other_eukaryote"
names(tax.euk3)=paste0("t",gsub("\\t.+$","",tax.euk))
taxDB=c(tax.simple,tax.euk3)
taxDB=taxDB[order(as.numeric(gsub("^t","",names(taxDB))))]
fasta_con=file(paste0("tmp/",timestamp,"/",timestamp,"_dump.fasta"))
open(fasta_con,open="r")
while(TRUE)
{
start=Sys.time()
chunk=scan(fasta_con,n=2000000,what="char",sep="\t",quote="") 
if(length(chunk)==0)
{
break
}else
{
chunk=matrix(chunk,byrow=T,ncol=4)
nprot=nrow(chunk)
chunk[,2]=paste0("t",chunk[,2])
chunk=cbind(chunk,taxDB[chunk[,2]])
chunk[is.na(chunk[,5]),5]="TaxMissingNCBI"  
new.header=paste0(chunk[,1],":",chunk[,2],":",chunk[,5]," ",chunk[,3])
new.fasta=c(rbind(new.header,chunk[,4]))
write.table(new.fasta,paste0("tmp/",timestamp,"/",timestamp,"_tax.fasta"),append=T,quote=F,row.names=F,col.names=F)
stop=Sys.time()
cat (paste0("Processed ",nprot," proteins.\n"))
print(stop-start)
}
}
close(fasta_con)
fasta.crc=jacksum(paste0("tmp/",timestamp,"/",timestamp,"_tax.fasta"))
dir.create(paste0(what,"/",fasta.crc))
fa_outfile=paste0(what,"/",fasta.crc,"/",fasta.crc,"_",what,"_tax.fasta")
file.rename(paste0("tmp/",timestamp,"/",timestamp,"_tax.fasta"),fa_outfile)
json_outfile=paste0(what,"/",fasta.crc,"/",info_outfile)
file.rename(paste0("tmp/",timestamp,"/",info_outfile),json_outfile)
if(grepl("M",toupper(opt[["format"]])))
{
dir.create(paste0(what,"/",fasta.crc,"/mmseqs"))
mmseqs.cmd=paste0(mmseqs.bin," createdb ",fa_outfile," ",paste0(what,"/",fasta.crc,"/mmseqs/",fasta.crc,"_",what,"_tax.db"))
system(mmseqs.cmd)
logtext=paste(what,json_outfile,info.md5,fasta.crc,paste0(what,"/",fasta.crc,"/mmseqs/",fasta.crc,"_",what,"_tax.db"),fasta.crc,num_prot_out,taxdump.crc32,Sys.time(),"mmseqs","yes",sep="_#_")
#unlist(strsplit(logtext,"_#_"))

log_DB_add(paste0(opt[["userdir"]],"/db_inventory.txt"),what,logtext)
}
if(grepl("D",toupper(opt[["format"]])))
{
dir.create(paste0(what,"/",fasta.crc,"/diamond"))
diamond.cmd=paste0("diamond makedb --in ",fa_outfile," -d",paste0(what,"/",fasta.crc,"/diamond/",fasta.crc,"_",what,"_tax.db"))
system(diamond.cmd)
logtext=paste(what,json_outfile,info.md5,fasta.crc,paste0(what,"/",fasta.crc,"/diamond/",fasta.crc,"_",what,"_tax.db"),fasta.crc,num_prot_out,taxdump.crc32,Sys.time(),"mmseqs","yes",sep="_#_")
log_DB_add(paste0(opt[["userdir"]],"/db_inventory.txt"),what,logtext)
}
unlink(paste0("tmp/",timestamp),recursive=T)
}

fetch.uniprot=function(x)
{
system(x[["command"]])
data.outfile=gsub("^.+ -O tmp","tmp",x[["command"]])
data.md5.obs=substr(system(paste0("md5sum ",data.outfile),intern=T),1,32)
if(!file.info(data.outfile)$size!=x[["size"]] && data.md5.obs!=x[["md5"]])
{
byedie(paste0("File size or MD5 signature mismatch detected!\nDownload failed for database \'",what,"\'!"))
}else{return(data.outfile)}
}

dl.uniprot=function(wd=opt[["userdir"]],sd=startdir,i=DBinfo,what)
{
setwd(wd)
if(!dir.exists(what))
{
dir.create(what)
}
taxDB.file=dl.ncbi_tax(wd=opt[["userdir"]],sd=startdir)
setwd(wd)
taxdump.crc32=jacksum(taxDB.file)
info(paste0("Fetching database \'",what,"\' from Expasy.\n"))
timestamp=paste0(what,"_",format(Sys.time(),"%Y%m%d%H%M"))
dir.create(paste0("tmp/",timestamp))
info_outfile=gsub("^.+/","",i[what,"DB_URL"])
info.download.cmd=paste0("wget --no-check-certificate  ",i[what,"DB_URL"]," -O tmp/",timestamp,"/",info_outfile)
system(info.download.cmd)
info.md5=substr(system(paste0("md5sum tmp/",timestamp,"/",info_outfile),intern=T) ,1,32)
info.data=(xmlParse(paste0("tmp/",timestamp,"/",info_outfile)))
info.data=do.call(paste, as.list(capture.output(info.data)))
if(what=="uniref100")
{
info.data.decode=list()
info.data.decode[["uniref100.fasta.gz"]]=list()
info.data.decode[["uniref100.fasta.gz"]][["version"]]=gsub("^.+<version>","",gsub("</version>.+$","",info.data))
info.data.decode[["uniref100.fasta.gz"]][["md5"]]=gsub("^.+>","",gsub("</hash>.+$","",gsub("^.+<file name=\"uniref100.fasta.gz\">","",info.data)))
info.data.decode[["uniref100.fasta.gz"]][["size"]]=gsub("^.+>","",gsub("</size>.+$","",gsub("^.+<file name=\"uniref100.fasta.gz\">","",info.data)))
info.data.decode[["uniref100.fasta.gz"]][["command"]]=gsub(info_outfile,"uniref100.fasta.gz",info.download.cmd)
}else if (what=="uniprotKB")
{
info.data.decode=list()
info.data.decode[["uniprot_sprot.fasta.gz"]]=list()
info.data.decode[["uniprot_sprot.fasta.gz"]][["version"]]=gsub("^.+<version>","",gsub("</version>.+$","",info.data))
info.data.decode[["uniprot_sprot.fasta.gz"]][["md5"]]=gsub("^.+>","",gsub("</hash>.+$","",gsub("^.+<file name=\"uniprot_sprot.fasta.gz\">","",info.data)))
info.data.decode[["uniprot_sprot.fasta.gz"]][["size"]]=gsub("^.+>","",gsub("</size>.+$","",gsub("^.+<file name=\"uniprot_sprot.fasta.gz\">","",info.data)))
info.data.decode[["uniprot_sprot.fasta.gz"]][["command"]]=gsub(info_outfile,"uniprot_sprot.fasta.gz",info.download.cmd)
info.data.decode[["uniprot_trembl.fasta.gz"]]=list()
info.data.decode[["uniprot_trembl.fasta.gz"]][["version"]]=gsub("^.+<version>","",gsub("</version>.+$","",info.data))
info.data.decode[["uniprot_trembl.fasta.gz"]][["md5"]]=gsub("^.+>","",gsub("</hash>.+$","",gsub("^.+<file name=\"uniprot_trembl.fasta.gz\">","",info.data)))
info.data.decode[["uniprot_trembl.fasta.gz"]][["size"]]=gsub("^.+>","",gsub("</size>.+$","",gsub("^.+<file name=\"uniprot_trembl.fasta.gz\">","",info.data)))
info.data.decode[["uniprot_trembl.fasta.gz"]][["command"]]=gsub(info_outfile,"uniprot_trembl.fasta.gz",info.download.cmd)
}else if (what=="uniprotSP")
{
#this is for development only, downloading only the swiss prot part of uniprotKB
info.data.decode=list()
info.data.decode[["uniprot_sprot.fasta.gz"]]=list()
info.data.decode[["uniprot_sprot.fasta.gz"]][["version"]]=gsub("^.+<version>","",gsub("</version>.+$","",info.data))
info.data.decode[["uniprot_sprot.fasta.gz"]][["md5"]]=gsub("^.+>","",gsub("</hash>.+$","",gsub("^.+<file name=\"uniprot_sprot.fasta.gz\">","",info.data)))
info.data.decode[["uniprot_sprot.fasta.gz"]][["size"]]=gsub("^.+>","",gsub("</size>.+$","",gsub("^.+<file name=\"uniprot_sprot.fasta.gz\">","",info.data)))
info.data.decode[["uniprot_sprot.fasta.gz"]][["command"]]=gsub(info_outfile,"uniprot_sprot.fasta.gz",info.download.cmd)
}
dl_outputs=sapply(info.data.decode,FUN=fetch.uniprot)
out.fasta.file=paste0("tmp/",timestamp,"/",what,"_",info.data.decode[[1]][["version"]],".fasta")
gunzip.cmd=paste0("zcat ",paste(dl_outputs,collapse=" ")," >",out.fasta.file )

gunzip.res=system(gunzip.cmd)
if(!gunzip.res==0)
{
byedie(paste0("Database decompression failed for \'",what,"'\"."))
}
tax=readLines(taxDB.file)
tax=gsub("\\t\\|$","",tax)
tax.last=gsub("^.+\\t","",tax)
tax.simple=tax.last[tax.last%in%c("Archaea","Bacteria","Viruses")]
names(tax.simple)=paste0("t",gsub("\\t.+$","",tax[tax.last%in%c("Archaea","Bacteria","Viruses")]))
tax.euk=tax[tax.last=="Eukaryota"]
tax.euk2=mclapply(tax.euk,function(x) unlist(strsplit(x,"\\t\\|\\t")),mc.cores=opt[["cpu"]])
tax.euk3=sapply(tax.euk2,function(x) x[9])
tax.euk3[tax.euk3==""]="Other_eukaryote"
names(tax.euk3)=paste0("t",gsub("\\t.+$","",tax.euk))
taxDB=c(tax.simple,tax.euk3)
taxDB=taxDB[order(as.numeric(gsub("^t","",names(taxDB))))]
uni_con=file(out.fasta.file)
open(uni_con,open="r")
while(TRUE)
{
start=Sys.time()
chunk=readLines(uni_con,n=50000000) 
if(length(chunk)==0)
{
break
}else
{
fchar=substr(chunk,1,1)
headers=fchar==">"
nprot=sum(headers)
chunk.taxid=gsub("^.+TaxID=","t",chunk[headers])
chunk.taxid[chunk.taxid=="tN/A"]="t32644"
chunk.taxid=gsub(" .+","",chunk.taxid)
chunk.id=gsub(" .+$","",chunk[headers])
chunk.comment=gsub("^\\S+ ","",chunk[headers])
chunk.taxtext=taxDB[chunk.taxid]
chunk.taxtext[is.na(chunk.taxtext)]="TaxMissingNCBI"
newheaders=paste0(chunk.id,":",chunk.taxid,":",chunk.taxtext," ",chunk.comment)
chunk[headers]=newheaders
write.table(chunk,paste0("tmp/",timestamp,"/",what,"_",info.data.decode[[1]][["version"]],"_tax.tmp"),append=T,quote=F,row.names=F,col.names=F)
stop=Sys.time()
cat (paste0("Processed ",nprot," proteins.\n"))
print(stop-start)
}
}                  
close(uni_con)
fasta.crc=jacksum(paste0("tmp/",timestamp,"/",what,"_",info.data.decode[[1]][["version"]],"_tax.tmp"))
fasta.crc=gsub("\\s.+$","",fasta.crc)
dir.create(paste0(what,"/",fasta.crc))
out.taxfasta=paste0(what,"/",fasta.crc,"/",fasta.crc,"_",what,"_",info.data.decode[[1]][["version"]],"_tax.fasta")
num_prot_out=system(paste0('grep -c ">" ',out.taxfasta),intern=T)
file.rename(paste0("tmp/",timestamp,"/",what,"_",info.data.decode[[1]][["version"]],"_tax.tmp"),out.taxfasta)
unlink(paste0("tmp/",timestamp),recursive=T)
if(grepl("M",toupper(opt[["format"]])))
{
dir.create(paste0(what,"/",fasta.crc,"/mmseqs"))
mmseqs.cmd=paste0(mmseqs.bin," createdb ",out.taxfasta," ",paste0(what,"/",fasta.crc,"/mmseqs/",fasta.crc,"_",what,"_",info.data.decode[[1]][["version"]],"_tax.db"))
system(mmseqs.cmd)
logtext=paste(what,info_outfile,info.md5,fasta.crc,paste0(what,"/",fasta.crc,"/mmseqs/",fasta.crc,"_",what,"_",info.data.decode[[1]][["version"]],"_tax.db"),fasta.crc,num_prot_out,taxdump.crc32,Sys.time(),"mmseqs","yes",sep="_#_")
log_DB_add(paste0(opt[["userdir"]],"/db_inventory.txt"),what,logtext)
}
if(grepl("D",toupper(opt[["format"]])))
{
dir.create(paste0(what,"/",fasta.crc,"/diamond"))
diamond.cmd=paste0("diamond makedb --in ",out.taxfasta," -d ",paste0(what,"/",fasta.crc,"/diamond/",fasta.crc,"_",what,"_",info.data.decode[[1]][["version"]],"_tax.db"))
system(diamond.cmd)
logtext=paste(what,info_outfile,info.md5,fasta.crc,paste0(what,"/",fasta.crc,"/diamond/",fasta.crc,"_",what,"_tax.db"),fasta.crc,num_prot_out,taxdump.crc32,Sys.time(),"mmseqs","yes",sep="_#_")
log_DB_add(paste0(opt[["userdir"]],"/db_inventory.txt"),what,logtext)
}
}

########################################################################################
#check if the user database directory exists, is writeable and has at least 500 GB free space
########################################################################################
if(!dir.exists(opt[["userdir"]]))
{
info(paste0("Your local database repository folder \'",opt[["userdir"]],"\' does not exist!\n"))
ans=user.input("Do you want to create it now and proceed with a clean database install? (yes/no)\n")
 if(ans=="yes")
 {
 dir.status=try(create.dir(opt[["userdir"]]))
  if(!dir.status)
  {byedie(paste0("Local database repository folder \'",opt[["userdir"]],"\' could not be created.\n Please check folder path and permissions!\n"))}else{}
 }else
 {
 byedie(paste0('Download of \"',opt[["dbname"]],'\"'," database was cancelled by user.\n"))
 }
}

dbd.df=system(paste0("df -P ",opt[["userdir"]]," -B 1G ",opt[["userdir"]]),intern=T)[2]
dbd.dfv=unlist(strsplit(dbd.df," +"))
dbd.free=as.numeric(dbd.dfv[[4]])
if(!dbd.free>=500)
{
biedye(paste0("There seems to be less than 500 GHB free space in folder ",opt[["userdir"]],"!\n"))
}
#jump to user directory
setwd(opt[["userdir"]])

if(opt[["dbname"]]%in%c("nr_prot","refseq_prot","swissprot"))
{
dl.ncbi_blastdb(what=opt[["dbname"]])
}else if(opt[["dbname"]]%in%c("uniref100","uniprotKB","uniprotSP")){
dl.uniprot(what=opt[["dbname"]])
}else if(opt[["dbname"]]=="ncbi_taxonomy"){
dl.ncbi_tax()
}else
{
byedie(paste0("Database \'",opt[["dbname"]],"\' is not recognized!"))
}













